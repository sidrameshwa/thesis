{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-C88Ov2Sjz2F",
    "outputId": "12067180-6747-434a-af47-0b9c4877ec62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (2.3.0)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (1.10.4)\n",
      "Requirement already satisfied: docker<7,>=4.0.0 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (6.0.1)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: Flask<3 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (2.2.3)\n",
      "Requirement already satisfied: cloudpickle<3 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (2.2.1)\n",
      "Requirement already satisfied: gitpython<4,>=2.1.0 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (3.1.31)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (2.28.2)\n",
      "Requirement already satisfied: scipy<2 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (1.10.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (8.1.3)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (2.0.10)\n",
      "Requirement already satisfied: packaging<24 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (23.1)\n",
      "Requirement already satisfied: matplotlib<4 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (3.7.1)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (3.1.2)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (0.4.4)\n",
      "Requirement already satisfied: querystring-parser<2 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (1.2.4)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (6.6.0)\n",
      "Requirement already satisfied: databricks-cli<1,>=0.8.7 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (0.17.6)\n",
      "Requirement already satisfied: pandas<3 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (2.0.1)\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (4.22.3)\n",
      "Requirement already satisfied: pytz<2024 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (2023.3)\n",
      "Requirement already satisfied: gunicorn<21 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (20.1.0)\n",
      "Requirement already satisfied: pyarrow<12,>=4.0.0 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (11.0.0)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (6.0)\n",
      "Requirement already satisfied: numpy<2 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (1.24.3)\n",
      "Requirement already satisfied: entrypoints<1 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (0.4)\n",
      "Requirement already satisfied: scikit-learn<2 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from mlflow) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from alembic!=1.10.0,<2->mlflow) (4.5.0)\n",
      "Requirement already satisfied: Mako in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from alembic!=1.10.0,<2->mlflow) (1.2.4)\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.9.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from docker<7,>=4.0.0->mlflow) (1.5.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from docker<7,>=4.0.0->mlflow) (1.26.15)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from Flask<3->mlflow) (2.2.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from Flask<3->mlflow) (2.1.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from gitpython<4,>=2.1.0->mlflow) (4.0.10)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow) (5.0.0)\n",
      "Requirement already satisfied: setuptools>=3.0 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from gunicorn<21->mlflow) (58.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow) (3.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from matplotlib<4->mlflow) (9.5.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from matplotlib<4->mlflow) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from matplotlib<4->mlflow) (1.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from matplotlib<4->mlflow) (4.39.3)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from matplotlib<4->mlflow) (5.12.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from matplotlib<4->mlflow) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from matplotlib<4->mlflow) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from matplotlib<4->mlflow) (0.11.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from pandas<3->mlflow) (2023.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from scikit-learn<2->mlflow) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from scikit-learn<2->mlflow) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.1.1 is available.\n",
      "You should consider upgrading via the '/Users/thota/sid/thesis/env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YqO8bDK5qNXo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "H4fSupc5j-kM"
   },
   "outputs": [],
   "source": [
    "# Reading csv file \n",
    "data = pd.read_csv('Data/Data-set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "aYs794pUkB30",
    "outputId": "30a7ec1e-c58b-469f-baec-2854876c66dc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>239840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    value\n",
       "0   22976\n",
       "1  251288\n",
       "2  239840\n",
       "3   87320\n",
       "4   38352"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ADuU3Od9aJC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "vI7FEHZKkDGp"
   },
   "outputs": [],
   "source": [
    "#converting to list\n",
    "data = data.value.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uBxv2ap2kE-D"
   },
   "outputs": [],
   "source": [
    "#80% for training and 20% for testing\n",
    "# data preparation for training and testing\n",
    "train_index = int(len(data)*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ijoBr3iNkP9Y"
   },
   "outputs": [],
   "source": [
    "train = data[:train_index].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "zRM9N33KkTSD"
   },
   "outputs": [],
   "source": [
    "test = data[train_index:].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Wvdt2YzEkWMG"
   },
   "outputs": [],
   "source": [
    "# standardize data\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "gTzYIFCVkz5V"
   },
   "outputs": [],
   "source": [
    "train = scaler.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "h_A7k5x6lcqY"
   },
   "outputs": [],
   "source": [
    "test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "PBSFn-SNlkXg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# create data with a sliding window size 10 and step 1\n",
    "def create_sliding_window_data(arr, window_size=10):\n",
    "    X, y = [], []\n",
    "    for i in range(len(arr)-window_size):\n",
    "        # Create a window of size 10\n",
    "        window = arr[i:i+window_size]\n",
    "        # Append the window to the input X\n",
    "        X.append(window)\n",
    "        # Append the next element as the output y\n",
    "        y.append(arr[i+window_size])\n",
    "    \n",
    "    # Convert the input and output to NumPy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X.squeeze(), y.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PuR78gd0lqpG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aj5fjMWvmxGk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "SdqNpsz3t_JG",
    "outputId": "4ad2c993-cbcc-4d00-8c47-896ec2eee5bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Linear regression model\\nfrom sklearn.linear_model import LinearRegression\\n\\nmodel = LinearRegression()\\n\\n# Train the model on the data\\nmodel.fit(X_train, y_train)'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model on the data\n",
    "model.fit(X_train, y_train)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "LykceeEvuIz1",
    "outputId": "177405eb-4eaf-4685-e8c2-ae1b1ed8f96a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#testing the linear regression model\\ny_pred = model.predict(X_test)'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#testing the linear regression model\n",
    "y_pred = model.predict(X_test)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "qFp-veHq6U0t"
   },
   "outputs": [],
   "source": [
    "def log_scalar(name, value, step):\n",
    "    \"\"\"Log a scalar value to both MLflow and TensorBoard\"\"\"\n",
    "    mlflow.log_metric(name, value, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ZHi1yBEdHWuU"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# to create data loaders\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        x = self.x[i]\n",
    "        y = self.y[i]\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "R9pg_ksrnUZf"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from collections import namedtuple\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# Deep Regression model \n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, input_size = 10):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, 256)\n",
    "        self.linear2 = nn.Linear(256, 256)\n",
    "        self.linear3 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "# LSTM model\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size=64, input_size = 10):\n",
    "        super(MyLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape = (batch_size, sequence_length, input_size)\n",
    "        output, (hidden, cell) = self.lstm(x)\n",
    "        # output.shape = (batch_size, sequence_length, hidden_size)\n",
    "        # hidden.shape = (1, batch_size, hidden_size)\n",
    "        # cell.shape = (1, batch_size, hidden_size)\n",
    "        output = self.linear(hidden.squeeze().double())\n",
    "        # output.shape = (batch_size, 1)\n",
    "        return output\n",
    "\n",
    "#RNN model   \n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size = 10, hidden_size=64, output_size=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).double()\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim=10, output_dim=1, hidden_dim=32, num_layers=2, num_heads=2, dropout=0.3):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(hidden_dim, num_heads, hidden_dim, dropout)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = self.encoder(x)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResLSTM(nn.Module):\n",
    "    def __init__(self, input_size=10, hidden_size=64, num_layers=2, dropout=0.3):\n",
    "        super(ResLSTM, self).__init__()\n",
    "\n",
    "        # ResNet block as feature extractor\n",
    "        self.resnet = resnet18(pretrained=True)\n",
    "        self.resnet.fc = nn.Identity()\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "        # LSTM to process the extracted features\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "\n",
    "        # Fully connected layer for prediction\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.compressor = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape input data to match ResNet input\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.resnet(x)\n",
    "        # Pass ResNet features through LSTM\n",
    "        x = self.compressor(x)\n",
    "        x = x.view(x.size(0), 1, -1)\n",
    "        x, _ = self.lstm(x)\n",
    "\n",
    "        # Get the last output from LSTM and pass it through a fully connected layer for prediction\n",
    "        x = self.fc(x[:, -1, :])\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "#Define the model, loss function, and optimizer\n",
    "#model = RNN(input_size=params.window_size, hidden_size=10, output_size=1).double()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mduVf6j3ozLF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0y9ZcWAw2gc_",
    "outputId": "4d295357-ed04-4f34-82c4-c0887cac55fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: livelossplot in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (0.5.5)\n",
      "Requirement already satisfied: matplotlib in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from livelossplot) (3.7.1)\n",
      "Requirement already satisfied: bokeh in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from livelossplot) (3.1.0)\n",
      "Requirement already satisfied: tornado>=5.1 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from bokeh->livelossplot) (6.3.1)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from bokeh->livelossplot) (9.5.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from bokeh->livelossplot) (6.0)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from bokeh->livelossplot) (2023.2.0)\n",
      "Requirement already satisfied: pandas>=1.2 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from bokeh->livelossplot) (2.0.1)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from bokeh->livelossplot) (3.1.2)\n",
      "Requirement already satisfied: packaging>=16.8 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from bokeh->livelossplot) (23.1)\n",
      "Requirement already satisfied: contourpy>=1 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from bokeh->livelossplot) (1.0.7)\n",
      "Requirement already satisfied: numpy>=1.16 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from bokeh->livelossplot) (1.24.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.1.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from pandas>=1.2->bokeh->livelossplot) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from pandas>=1.2->bokeh->livelossplot) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from pandas>=1.2->bokeh->livelossplot) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=1.2->bokeh->livelossplot) (1.16.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from matplotlib->livelossplot) (4.39.3)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from matplotlib->livelossplot) (3.0.9)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from matplotlib->livelossplot) (5.12.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from matplotlib->livelossplot) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from matplotlib->livelossplot) (1.4.4)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/thota/sid/thesis/env/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->livelossplot) (3.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.1.1 is available.\n",
      "You should consider upgrading via the '/Users/thota/sid/thesis/env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install livelossplot\n",
    "import livelossplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "-Y_5_LVMFuIv"
   },
   "outputs": [],
   "source": [
    "from livelossplot import PlotLosses\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def trainer(params):\n",
    "  X_train, y_train = create_sliding_window_data(train, window_size = params['window_size'])\n",
    "  X_test, y_test = create_sliding_window_data(test, window_size = params['window_size'])\n",
    "\n",
    "  X_train = torch.from_numpy(X_train).double()\n",
    "  y_train = torch.from_numpy(y_train).double()\n",
    "\n",
    "  train_dataset = Data(X_train, y_train)\n",
    "  train_loader = DataLoader(train_dataset, batch_size = params['batch_size'], shuffle=True)\n",
    "\n",
    "  test_dataset = Data(X_test, y_test)\n",
    "  test_loader = DataLoader(test_dataset, batch_size = params['batch_size'], shuffle=True)\n",
    "\n",
    "  if params[\"model\"] ==\"resnet\":\n",
    "    model = ResLSTM().double()\n",
    "  elif params[\"model\"] == \"transformer\":\n",
    "    model = TransformerModel().double()\n",
    "  elif params[\"model\"] == \"rnn\":\n",
    "    model = RNN().double()\n",
    "  elif params[\"model\"] == \"lstm\":\n",
    "    model = MyLSTM().double()\n",
    "  else:\n",
    "    model = RegressionModel().double()\n",
    "\n",
    "  criterion = nn.MSELoss()\n",
    "  optimizer = optim.Adam(model.parameters(), lr= params['lr'])\n",
    "\n",
    "  with mlflow.start_run() as run:  \n",
    "    # Log our parameters into mlflow\n",
    "    for key, value in params.items():\n",
    "        mlflow.log_param(key, value)\n",
    "\n",
    "    print('Deep Learning models')\n",
    "    print('====================')\n",
    "\n",
    "    print('Training phase')\n",
    "\n",
    "    liveloss = PlotLosses()\n",
    "    for epoch in range(params['epochs']):\n",
    "\n",
    "        print(\"Active Run ID: %s, Epoch: %s \\n\" % (run.info.run_uuid, epoch+1))\n",
    "        total_loss = 0\n",
    "        logs = {}\n",
    "        i = 0\n",
    "        for X_train, y_train in train_loader:\n",
    "          i += 1\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          outputs = model(X_train.view(X_train.shape[0], 1, X_train.shape[-1]))\n",
    "          #outputs = model(X_train)\n",
    "          loss = criterion(outputs.squeeze(), y_train)\n",
    "          total_loss += loss.item()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "        print('Epoch {}, Loss: {:.4f}'.format(epoch+1, total_loss/i))\n",
    "        logs['MSE loss'] = total_loss/i \n",
    "        liveloss.update(logs)\n",
    "        liveloss.send()\n",
    "        log_scalar('train_loss', total_loss/i, epoch)\n",
    "\n",
    "    torch.save(model.state_dict(), f\"{params['model']}_{params['epochs']}_{params['batch_size']}_{params['window_size']}.pth\")\n",
    "    \n",
    "    print('Test Phase')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        i = 0\n",
    "        for X_test, y_test in test_loader:\n",
    "          i += 1\n",
    "          outputs = model(X_test.view(X_test.shape[0], 1, X_test.shape[-1]))\n",
    "          #outputs = model(X_test)\n",
    "          \n",
    "          total_loss += criterion(outputs, y_test)\n",
    "        print('Loss: {:.4f}'.format(total_loss.item()/i))\n",
    "        log_scalar('test_loss', total_loss/i, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YC-xuEkNpQ0U",
    "outputId": "be30980a-1e9c-4a0b-8fff-a1ee2f83ab1c"
   },
   "outputs": [
    {
     "ename": "RestException",
     "evalue": "INVALID_PARAMETER_VALUE: Response: {'error_code': 'INVALID_PARAMETER_VALUE'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestException\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m32\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m100\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwindow_size\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m }\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 31\u001b[0m, in \u001b[0;36mtrainer\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     28\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m     29\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m run:  \n\u001b[1;32m     32\u001b[0m   \u001b[38;5;66;03m# Log our parameters into mlflow\u001b[39;00m\n\u001b[1;32m     33\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     34\u001b[0m       mlflow\u001b[38;5;241m.\u001b[39mlog_param(key, value)\n",
      "File \u001b[0;32m~/sid/thesis/env/lib/python3.9/site-packages/mlflow/tracking/fluent.py:350\u001b[0m, in \u001b[0;36mstart_run\u001b[0;34m(run_id, experiment_id, run_name, nested, tags, description)\u001b[0m\n\u001b[1;32m    346\u001b[0m         user_specified_tags[MLFLOW_RUN_NAME] \u001b[38;5;241m=\u001b[39m run_name\n\u001b[1;32m    348\u001b[0m     resolved_tags \u001b[38;5;241m=\u001b[39m context_registry\u001b[38;5;241m.\u001b[39mresolve_tags(user_specified_tags)\n\u001b[0;32m--> 350\u001b[0m     active_run_obj \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp_id_for_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_tags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_name\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m _active_run_stack\u001b[38;5;241m.\u001b[39mappend(ActiveRun(active_run_obj))\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _active_run_stack[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/sid/thesis/env/lib/python3.9/site-packages/mlflow/tracking/client.py:280\u001b[0m, in \u001b[0;36mMlflowClient.create_run\u001b[0;34m(self, experiment_id, start_time, tags, run_name)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_run\u001b[39m(\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    231\u001b[0m     experiment_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     run_name: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    235\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Run:\n\u001b[1;32m    236\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m    Create a :py:class:`mlflow.entities.Run` object that can be associated with\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m    metrics, parameters, artifacts, etc.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;03m        status: RUNNING\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sid/thesis/env/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py:131\u001b[0m, in \u001b[0;36mTrackingServiceClient.create_run\u001b[0;34m(self, experiment_id, start_time, tags, run_name)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# Extract user from tags\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# This logic is temporary; the user_id attribute of runs is deprecated and will be removed\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# in a later release.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m user_id \u001b[38;5;241m=\u001b[39m tags\u001b[38;5;241m.\u001b[39mget(MLFLOW_USER, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mget_current_time_millis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mRunTag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sid/thesis/env/lib/python3.9/site-packages/mlflow/store/tracking/rest_store.py:175\u001b[0m, in \u001b[0;36mRestStore.create_run\u001b[0;34m(self, experiment_id, user_id, start_time, tags, run_name)\u001b[0m\n\u001b[1;32m    165\u001b[0m tag_protos \u001b[38;5;241m=\u001b[39m [tag\u001b[38;5;241m.\u001b[39mto_proto() \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m tags]\n\u001b[1;32m    166\u001b[0m req_body \u001b[38;5;241m=\u001b[39m message_to_json(\n\u001b[1;32m    167\u001b[0m     CreateRun(\n\u001b[1;32m    168\u001b[0m         experiment_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(experiment_id),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m     )\n\u001b[1;32m    174\u001b[0m )\n\u001b[0;32m--> 175\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCreateRun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m run \u001b[38;5;241m=\u001b[39m Run\u001b[38;5;241m.\u001b[39mfrom_proto(response_proto\u001b[38;5;241m.\u001b[39mrun)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run\n",
      "File \u001b[0;32m~/sid/thesis/env/lib/python3.9/site-packages/mlflow/store/tracking/rest_store.py:56\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[0;34m(self, api, json_body)\u001b[0m\n\u001b[1;32m     54\u001b[0m endpoint, method \u001b[38;5;241m=\u001b[39m _METHOD_TO_INFO[api]\n\u001b[1;32m     55\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mResponse()\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sid/thesis/env/lib/python3.9/site-packages/mlflow/utils/rest_utils.py:290\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[0;34m(host_creds, endpoint, method, json_body, response_proto)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m     response \u001b[38;5;241m=\u001b[39m http_request(\n\u001b[1;32m    288\u001b[0m         host_creds\u001b[38;5;241m=\u001b[39mhost_creds, endpoint\u001b[38;5;241m=\u001b[39mendpoint, method\u001b[38;5;241m=\u001b[39mmethod, json\u001b[38;5;241m=\u001b[39mjson_body\n\u001b[1;32m    289\u001b[0m     )\n\u001b[0;32m--> 290\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mverify_rest_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m js_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m    292\u001b[0m parse_dict(js_dict\u001b[38;5;241m=\u001b[39mjs_dict, message\u001b[38;5;241m=\u001b[39mresponse_proto)\n",
      "File \u001b[0;32m~/sid/thesis/env/lib/python3.9/site-packages/mlflow/utils/rest_utils.py:214\u001b[0m, in \u001b[0;36mverify_rest_response\u001b[0;34m(response, endpoint)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _can_parse_as_json_object(response\u001b[38;5;241m.\u001b[39mtext):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RestException(json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext))\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m         base_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI request to endpoint \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m failed with error code \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m != 200\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    217\u001b[0m             endpoint,\n\u001b[1;32m    218\u001b[0m             response\u001b[38;5;241m.\u001b[39mstatus_code,\n\u001b[1;32m    219\u001b[0m         )\n",
      "\u001b[0;31mRestException\u001b[0m: INVALID_PARAMETER_VALUE: Response: {'error_code': 'INVALID_PARAMETER_VALUE'}"
     ]
    }
   ],
   "source": [
    "params = {'lr' : 0.001, 'batch_size': 32, 'epochs':100, 'window_size':10, 'model': \"transformer\" }\n",
    "trainer(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0l9CurtJPvhN"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
